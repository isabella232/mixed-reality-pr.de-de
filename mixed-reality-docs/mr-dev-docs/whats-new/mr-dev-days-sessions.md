---
title: Mixed Reality Dev Days-Sitzungsaufzeichnungen
description: Sitzungsseite mit Videolinks für MR Dev Days
author: jessemcculloch
ms.author: jemccull
ms.date: 02/21/2020
ms.topic: article
keywords: Mixed Reality, Conference, Conference, Conference, Developer, HoloLens, HoloLens 2, Kinect
ms.openlocfilehash: b0fbb0d587470d72c436981443c80299a62b2645b9b860b3abe0b05726930871
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 08/05/2021
ms.locfileid: "115209780"
---
# <a name="session-details-and-recordings"></a>Sitzungsdetails und Aufzeichnungen

![Mixed Reality Dev Days](images/MRDD/MRDevDaysBanner.png)

|**Sitzungstitel**|**Referent**|**Beschreibung**|
|---------|---------|---------|
|[Opening Keynote](https://aka.ms/MRDDKeynote)|Alex Kipman|Alex Kipman startet unser erstes virtuelles Mixed Reality Dev Days-Ereignis.|
|[Einführung in Azure Mixed Reality Services: Azure Remote Rendering](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Remote-Rendering)|Ungals, Manthei und Appels ( Appels)|Azure Remote Rendering soeben in die öffentliche Vorschauversion ein.  Erfahren Sie, wie ARR interaktive 3D-Modelle mit Hunderten von Millionen von Polygonen auf Geräte wie HoloLens 2 in Echtzeit rendert und streamt.|
|[Einführung in Unreal + MRTK für HoloLens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Unreal--MRTK-for-HoloLens-2)|Sommer wu & Luis Valverde|Die Unreal Engine-Unterstützung für HoloLens 2 wurde im Mai mit der Veröffentlichung von UE 4.25 in die Produktion vorbereitet! Neben UE 4.25 hat unser Team die erste Komponente des Mixed Reality Toolkits für Unreal veröffentlicht, nachdem der HoloLens-Support von Unreal erstmals in der Vorschau veröffentlicht wurde. In diesem Artikel erhalten Sie einen Überblick über die Features von Unreal Engine 4 und MRTK für Unreal und deren Verwendung zum Erstellen von epic-Erfahrungen für HoloLens 2.|
|[Erste Schritte mit dem HoloLens 2 und Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Getting-started-with-the-HoloLens-2-and-Unity)|Dan Miller – Unity|Lernen Sie die Grundlagen der Einrichtung von Unity und der Entwicklung für die HoloLens 2. In dieser Präsentation werden bewährte Methoden, grundlegende Features des HoloLens 2 und das schnelle Hinzufügen von Unterstützung für handtracking und Interaktivität mit nativen Unity-APIs|
|[Einführung in Azure Mixed Reality Services: Azure Spatial Anchors](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Spatial-Anchors)|Archana Iyer & Meldete Rivera|Eine Übersicht über Azure Spatial Anchors (ASA) und relevante Szenarien. In dieser Rede werden neue Funktionen, die im letzten Jahr entwickelt wurden, mit Codebeispielen zur Verwendung dieser Funktionen durchgehen. Wir gehen auf bewährte Methoden beim Erstellen mit ASA ein und erfahren, wie Sie mit der Integration in Ihre Produkte beginnen können.|
|[Einführung in MRTK-Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-MRTK-Unity)|Catherine Diaz|Die Einführung in die MRTK-Sitzung ist ein Tutorial zum Erstellen einer MRTK-App von Anfang bis Ende.  Dieser Artikel geht auf Interaktionskonzepte ein und zeigt die Funktionen des MRTK für mehrere Plattformen.|
|[Lernen aus der MR-Oberflächen-App](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Learnings-from-the-MR-Surfaces-App)|Lars Simkins|Treten Sie den Technikern hinter der ICHL-Oberflächen-App für HoloLens 2, während sie über die Entwurfsgeschichte und die technischen Highlights der App sprechen.|
|[Azure Kinect Body Tracking Unity-Integration](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Azure-Kinect-Body-Tracking-Unity-Integration)|Anili Antley| Erfahren Sie, wie Sie Zeichen in Unity mit dem Azure Kinect Body Tracking SDK steuern.|
|[UX-Bausteine des MRTK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTKs-UX-Building-Blocks)|Yoon Park|Hier erhalten Sie einen tieferen Blick auf die UX-Komponenten des MRTK, die Ihnen beim Erstellen von mixed reality-Erfahrungen helfen.|
|[MRTK-Leistungstools](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Performance-and-Shaders)|David Kline& Einer der 16666-Erdungs-&|Eine Einführung in Leistungstools, sowohl im MRTK als auch extern, sowie eine Übersicht über den MRTK-Standard-Shader.|
|[Status der Mixed Reality– Wo Unternehmen Erfolg finden](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/The-State-of-Mixed-Reality-Where-Companies-are-finding-Success)|Ori Amsai & Matt Sollstein|Edge Computing mit extrem geringer Latenz in Verbindung mit KI und Mixed Reality ist die Grundlage für die nächste Generation von Erfahrungen. Durch die Mischung aus digitaler und physischer Welt in ubiquitierte Computingumgebungen ermöglicht Mixed Reality Möglichkeiten, von denen wir zuvor nur geträumt haben konnten. In dieser Sitzung bieten Ori und Matt einzigartige Einblicke in die Mixed Reality-Marktchance heute und in der Zukunft. Sie werden hervorheben, wie Microsoft führende Unternehmen in Denk-, Gesundheits- und Einzelhandelsunternehmen dabei unterstützt, die Leistungsfähigkeit von Mixed Reality zu nutzen, um die Geschäftseffizienz zu steigern und kunden- und mitarbeiterorientierte Erfahrungen zu transformieren.|
|[Fireside Chat](https://aka.ms/MRDDFireside)|Alex Kipman & Fürst Schulte|Am ersten Tag 2 haben wir Microsoft MVP, Regional Director und community member extraordinordin native Schulte eingeladen, um sich über die Themen zu informieren, die für die Community von Interesse sind. Seit etwa einer Woche sammeltE Erding Fragen aus der Community, und wir gehen davon aus, dass es sich um eine gute Unterhaltung wird.|
|[Entwerfen von AR/VR-Erfahrungen mit Microsoft Maquette](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Designing-ARVR-experiences-using-Microsoft-Maquette)|Acchef|Das Entwerfen einer Telefon-App oder einer Website verfügt über einen klar definierten Workflow. Leider kann das Entwerfen räumlicher Realitätserfahrungen aufgrund seiner Unentität schwierig sein, wenn Sie denselben 2D-Workflow oder das gleiche Toolset verwenden. Glücklicherweise konzentriert sich die neue Microsoft Maquette-App darauf, UX-Designer beim Entwerfen zu unterstützen.|
|[MRTK Unity v2 &: Wie community feedback uns bei der Verbesserung des MRTK unterstützt hat](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Unity-v2-and-beyond-How-community-feedback-helped-us-improve-MRTK)|Solladette Thalthal|Ein Gespräch darüber, wie wir die Entwicklererfahrung im letzten Jahr verbessert haben, indem wir auf Feedback aus der Community lauschen und wie Entwickler diese Verbesserungen nutzen können. Wir untersuchen die Dokumentation und Komponententests, die neue Objektmanipulatorkomponente, mithilfe des Migrationsfensters und untersuchen einige Codeausschnitte zu unseren am häufigsten gestellten Fragen aus der Entwickler-Community.|
|[Unreal Engine-Plug-In von Dark Slope für azure Kinect DK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Dark-Slopes-Unreal-Engine-plugin-for-the-Azure-Kinect-DK)|Ben Unsworth – Dunkle Steigung|Erfahren Sie, wie Dark Slope das Azure Kinect DK und seine SDKs verwendet, um interaktive Echtzeitengagements in Unreal Engine zu erstellen.|
|[Einführung in StereoKit – MR Made Easy!](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Introducing-StereoKit-MR-Made-Easy)|Zwischen ihnen|StereoKit ist eine einfach zu verwendende Open-Source-Mixed Reality-Bibliothek zum Erstellen HoloLens- und VR-Anwendungen mit C# und OpenXR! StereoKit priorisiert die Entwicklung von Mixed Reality-Anwendungen vor allem, sodass Features wie ein erstklassiges Mixed Reality-Eingabesystem, eine schnelle Leistung standardmäßig auch auf mobilen Geräten, eine schnelle Iterationszeit auf dem Gerät und eine Laufzeitressourcenpipeline ermöglicht werden, mit der Benutzer und Entwickler echte Ressourcen aus dem Dateisystem laden können. All dies und mehr sind in einer knappen API gepackt, die gut dokumentiert, leicht zu erlernen und einfach zu schreiben ist!|
|[Erstellen immersiver MR-Erfahrungen mit Babylon.js und WebXR](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Building-Immersive-MR-Experiences-with-Babylonjs-and-WebXR)|Jason Carter & Raanan Moderator|Erfahren Sie, wie einfach und leistungsfähig es sein kann, MR-Erfahrungen direkt im Web zu entwickeln. Babylon.js zielte darauf ab, eine der leistungsstärksten, besten, einfachsten und offenen Webrenderingplattformen der Welt zu sein, wodurch es einfach ist, vollständige MR-Funktionen plattform-, geräte- und ökosystemübergreifend zu nutzen. Sehen Sie sich die neuesten Entwicklungen von Babylon.js und die Unterstützung von WebXR an.|
|[Verwenden Project Acoustics mit HoloLens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Using-Project-Acoustics-with-HoloLens-2)|Mike Vordenkung|Erfahren Sie, Project Akustik, die bisher nur für VR- und Konsolentitel verfügbar war, auf die Mixed Reality! Erfahren Sie, wie das System reale Effekte wie diffracted occlusion und redirection von Sounds um physische Tür- und Eckentüren und Hall in komplexen Geometrien mit mehreren verbundenen Räumen neu erstellt, die alle innerhalb des Computebudgets eines HoloLens 2.|
|[Holographic Remoting – Schnelle Iteration & auf HoloLens](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Holographic-Remoting-Rapid-iteration-and-superharged-graphics-on-HoloLens)|Brent Gegen|HoloLens bietet wie keine andere eine sehr mobile Computing-Plattform, ist aber auf die Verarbeitungsleistung eines mobilen Geräts beschränkt. Holographic Remoting bringt die Rohleistung eines VR-fähigen Computers in HoloLens, und mit Unity-Remoting im Editor müssen Sie Ihre Apps nicht mehr erstellen und bereitstellen, um sie auf einem Gerät zu testen. Erfahren Sie, wie Holographic Remoting die Leistung Ihrer Anwendungen und Ihrer Entwickler steigern kann.|
|[OpenXR on HoloLens 2: Plattformübergreifende native Mixed Reality](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/OpenXR-on-HoloLens-2-Cross-platform-native-mixed-reality)|Alex Turner|OpenXR 1.0 ist hier! Erstellen Sie Mixed Reality-Unterstützung von Grund auf in Ihre eigene Engine oder native App? Wenn ja, erfahren Sie mehr über die wichtigsten Details der nativen OpenXR-API-Oberfläche, die Erweiterungen, die den vollständigen Funktionssatz von HoloLens 2 zum Leben bringen, und die Partner von Firefox Reality bis StereoKit, die bereits Apps und Frameworks auf Grundlage von OpenXR versenden! Mit OpenXR können Sie anbieterübergreifende Mixed Reality-Engines und native Apps erstellen, die die Breite der Geräte in der Branche umfassen.|
|[Tipps aus einem Jahr HoloLens 2 Entwicklung](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Tips-from-a-Year-of-HoloLens-2-Development)|Peter Vale|Das HoloLens-Kommerzialisierungsteam gibt Tipps und Erkenntnisse aus dem letzten Jahr, die wir mit unseren Partnern gewonnen haben.  Erhalten Sie Einblicke in die häufigsten Probleme sowie bewährte Methoden und Techniken, die Sie verwenden können, um Ihre HoloLens 2-Anwendung für die Freigabe mit Ihren Kunden bereit zu machen.|
|||||

--- 
